1. AI Agents & Automation:
 ollama:
    pull ollama model: ollama pull llama3.2
    run ollama model : ollama run llama3.2
    The default connection URL for Ollama is typically http://localhost:11434.
 n8n:
    docker volume create n8n_data
    docker run -it --rm --name n8n -p 5678:5678 -v n8n_data:/home/node/.n8n docker.n8n.io/n8nio/n8n
    to access ollama from within the n8n cluster, the connect url: http://host.docker.internal:11434

2. venv â€” Creation of virtual environments
 create a venv:
    python -m venv my_env_name
    python3 -m venv .venv
 
 source the venv:
    source my_env_name/bin/activate
    source .venv/bin/activate
 
 Install ipykernel within the activated virtual environment:
 Install the ipykernel library into the virtual environment so we can make it available to Jupyter.
    pip install ipykernel
 
 Register the virtual environment as a Jupyter kernel:
 Use the ipykernel library to install our virtual environment for use with Jupyter.
    python -m ipykernel install --user --name .venv --display-name "My GENAI Workbench"
 
 List Virtual Environmentsin Jupyter Notebook:
    jupyter kernelspec list
 
 Remove Virtual Environment from Jupyter Notebook:
    jupyter kernelspec uninstall my_env_name

 Conversion from .py to .ipynb and vice-versa:
    pip install ipynb-py-convert
    ipynb-py-convert your_script.py your_notebook.ipynb

3. tcpdump:
  sudo tcpdump -n -i ens3 -A -s 0 -w /tmp/agen1.pcap 'host jcsdev.oracloud.caesars.com and (tcp port 80 or tcp port 443)' &
  sudo tcpdump -n -i ens3 -A -s 0 -w /tmp/agen1.pcap host 10.x.x.x &
  sudo tcpdump -ttttnnr /tmp/agen1.pcap
  
  https://gist.github.com/r0mdau/93ec268ad1ffeeaf99d80eba9e9ea84d
  https://github.com/pgillich/kubeadm-vagrant/blob/master/Ubuntu/capture_pod.sh
  # find the kube node of the running pod, appear next to hostIP, and note containerID hash
  kubectl get pod mypod -o json
  # -> save hostIP
  # -> save containerID
  
  # connect to the node and find the pods unique network interface index inside it's container
  docker exec containerID /bin/bash -c 'cat /sys/class/net/eth0/iflink'
  # -> returns index
  
  # locate the interface of the node
  ip link |grep ^index:
  # -> returns interface
  
  # then GO tcpdump !
  sudo tcpdump -i interface
  
  e.g.,
  kubectl get pods -n integrationrt-0 -o wide
  # -> take tech-adapters-5bdfb9865c-kfnws
  kubectl exec -it tech-adapters-5bdfb9865c-kfnws -n integrationrt-0 -- cat /sys/class/net/eth0/iflink
  # -> returns index
  ssh -F /Users/ramgudla/.ssh/oc1_prod_config/PHX-DPG32-cell4 10.211.2.175
  # <-> ssh to node
  ip link | grep ^153:
  # -> returns host side interface of the pod
  sudo tcpdump -n -i veth55310ab1 host www.google.com

  Capturing in the container network namespace:
  sudo docker inspect --format '{{ .State.Pid }}' k8s_nginx_my-nginx-b7d7bc74d-zxx28_default_ae4ee834-fb5d-4ec4-86b1-7834e538c666_0
  sudo nsenter -t 17900 -n /bin/bash -xec 'ip a; tcpdump -i eth0 -s 0 -Xvv tcp port 80'

  kubectl exec my-app-pod -c nginx -- tcpdump -i eth0 -w - | wireshark -k -i -

4. How to execute a command inside a docker container's network namespace:
  ## set up named network namespace
  POD="my-pod"
  NS_NAME="my-pod-nw-ns"
  docker ps | grep $POD | awk '{ print $1 }'
  cid=$(docker ps | grep $POD | awk '{ print $1 }')
  ## host side process id
  pid="$(docker inspect -f '{{.State.Pid}}' $cid)"
  mkdir -p /var/run/netns
  rm /var/run/netns/$NS_NAME 2>/dev/null
  ## creating named network namespace
  ln -s /proc/$pid/ns/net /var/run/netns/$NS_NAME
  ## run commands inside network namespace
  ip netns exec $NS_NAME hostname
  ip netns exec $NS_NAME ip a
  ip netns exec $NS_NAME sh -c 'echo "add your command here"'
  ## TCP packet capture inside namespace
  ip netns exec $NS_NAME tcpdump -i eth0 -n

5. tcp port forwarding:
  sudo yum install socat
  socat:
    https://copyconstruct.medium.com/socat-29453e9fc8a6
    https://fossies.org/linux/socat/EXAMPLES
  socat tcp-listen:8001,reuseaddr,fork tcp:localhost:8000
  socat TCP-LISTEN:8080,fork,reuseaddr TCP:google.com:443 

6. open local firewall on a VM:
  sudo firewall-cmd --zone=public --permanent --add-port=8081/tcp
  sudo firewall-cmd --reload

7. webserver:
while true; do cat response.json | nc -l 8000; done &

$ vi response.json
HTTP/1.1 200 OK
Content-Type: application/json; charset=UTF-8
Server: netcat!

{"msg":"Hello, Rama!"}

8. Fn:
 FROM fnproject/fn-java-fdk-build:jdk17-1.0.177 as build-stage
 WORKDIR /function
 ENV MAVEN_OPTS -Dhttp.proxyHost= -Dhttp.proxyPort= -Dhttps.proxyHost= -Dhttps.proxyPort= -Dhttp.nonProxyHosts= -Dmaven.repo.local=/usr/share/maven/ref/repository
 ADD pom.xml /function/pom.xml
 RUN ["mvn", "package", "dependency:copy-dependencies", "-DincludeScope=runtime", "-DskipTests=true", "-Dmdep.prependGroupId=true", "-DoutputDirectory=target", "--fail-never"]
 ADD src /function/src
 RUN ["mvn", "package"]
 FROM fnproject/fn-java-fdk:jre17-1.0.177
 WORKDIR /function
 COPY --from=build-stage /function/target/*.jar /function/app/
 ENV FN_FORMAT http-stream
 CMD ["com.example.fn.HelloFunction::handleRequest"]
 
 # https://github.com/fnproject/fdk-java/blob/master/runtime/src/main/java/com/fnproject/fn/runtime/HTTPStreamCodec.java
 # https://gist.github.com/recursivecodes/0ceb5974153d2bacc2aa5cba4ba42961
 # https://superuser.com/questions/1411402/how-to-expose-linux-socket-file-from-docker-container-mysql-mariadb-etc-to
 # Mount the common functions folder from host to container, and then on your host the socket will be available as /fn/ocid1.fn.test:
 # docker run -v /fn:/fn -e FN_LISTENER='unix:/fn/ocid1.fn.test' testfn
 # docker run -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh
 # curl -vvv --unix-socket /fn/ocid1.fn.test -H "Fn-Deadline: 2023-07-31T23:01:58Z"  -H "Fn-Call-Id: test" http://rg/call

